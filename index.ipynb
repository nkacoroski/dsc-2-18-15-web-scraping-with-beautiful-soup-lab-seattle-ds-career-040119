{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Now that you've read and seen some docmentation regarding the use of Beautiful Soup, its time to practice and put that to work! In this lab you'll formalize some of our example code into functions and scrape the lyrics from an artist of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Scrape Static webpages\n",
    "* Select specific elements from the DOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Scraping\n",
    "\n",
    "Write a function to collect the links to each of the song pages from a given artist page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starter Code\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_links(url):\n",
    "    html_page = requests.get(url) \n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "\n",
    "    #The example from our lecture/reading\n",
    "    data = [] #Create a storage container\n",
    "    albums = soup.find_all(\"div\", class_=\"album\")\n",
    "    for album_n in range(len(albums)):\n",
    "        #On the last album, we won't be able to look forward\n",
    "        if album_n == len(albums)-1:\n",
    "            cur_album = albums[album_n]\n",
    "            album_songs = cur_album.findNextSiblings('a')\n",
    "            for song in album_songs:\n",
    "                page = song.get('href')\n",
    "                title = song.text\n",
    "                album = cur_album.text\n",
    "                data.append((title, page, album))\n",
    "        else:\n",
    "            cur_album = albums[album_n]\n",
    "            next_album = albums[album_n+1]\n",
    "            saca = cur_album.findNextSiblings('a') #songs after current album\n",
    "            sbna = next_album.findPreviousSiblings('a') #songs before next album\n",
    "            album_songs = [song for song in saca if song in sbna] #album songs are those listed after the current album but before the next one!\n",
    "            for song in album_songs:\n",
    "                page = song.get('href')\n",
    "                title = song.text\n",
    "                album = cur_album.text\n",
    "                data.append((title, page, album))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Scraping\n",
    "Write a secondary function that scrapes the lyrics for each song page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember to open up the webpage in a browser and control-click/right-click and go to inspect!\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#Example page\n",
    "\n",
    "url = 'https://www.azlyrics.com/lyrics/lilyallen/sheezus.html'\n",
    "\n",
    "def scrape_lyrics(page_url):\n",
    "    html_page = requests.get(page_url)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    main_page = soup.find('div', {\"class\": \"container main-page\"})\n",
    "    main_l2 = main_l2.find('div', {\"class\": \"row\"})\n",
    "    main_l3 = main_l3.find('div', {\"class\": \"col-xs-12 col-lg-8 text-center\"})\n",
    "    lyrics = main_13.find('div')[6].text\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizing\n",
    "Create a script using your two functions above to scrape all of the song lyrics for a given artist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "songs = get_links(\"https://www.azlyrics.com/g/gomez.html\")\n",
    "print(len(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://www.azlyrics.com\"\n",
    "lyrics = []\n",
    "for song in songs:\n",
    "    try:\n",
    "        url_sffx = song[1].replace('..','')\n",
    "        url = url_base + url_sffx\n",
    "        lyr = scrape_lyrics(url)\n",
    "        lyrics.append(lyr)\n",
    "    except:\n",
    "        lyrics.append(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 106\n"
     ]
    }
   ],
   "source": [
    "print(len(songs), len(lyrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "Generate two bar graphs to compare lyrical changes for the artist of your chose. For example, the two bar charts could compare the lyrics for two different songs or two different albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Get Miles, ../lyrics/gomez/getmiles.html, alb...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Whippin' Piccadilly, ../lyrics/gomez/whippinp...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Make No Sound, ../lyrics/gomez/makenosound.ht...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(78 Stone Wobble, ../lyrics/gomez/78stonewobbl...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Tijuana Lady, ../lyrics/gomez/tijuanalady.htm...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1\n",
       "0  (Get Miles, ../lyrics/gomez/getmiles.html, alb...  N/A\n",
       "1  (Whippin' Piccadilly, ../lyrics/gomez/whippinp...  N/A\n",
       "2  (Make No Sound, ../lyrics/gomez/makenosound.ht...  N/A\n",
       "3  (78 Stone Wobble, ../lyrics/gomez/78stonewobbl...  N/A\n",
       "4  (Tijuana Lady, ../lyrics/gomez/tijuanalady.htm...  N/A"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(songs, lyrics)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level - Up\n",
    "\n",
    "Think about how you structured the data from your web scraper. Did you scrape the entire song lyrics verbatim? Did you simply store the words and their frequency counts, or did you do something else entirely? List out a few different options for how you could have stored this data. What are advantages and disadvantages of each? Be specific and think about what sort of analyses each representation would lend itself to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this block for your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've now practiced your Beautiful Soup knowledge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
